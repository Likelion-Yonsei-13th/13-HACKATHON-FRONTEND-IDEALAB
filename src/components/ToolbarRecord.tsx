// components/ToolbarRecord.tsx
"use client";

import { useEffect, useRef, useState } from "react";
import { PiMicrophoneFill, PiStopFill } from "react-icons/pi";

// =================== ì„¤ì • ===================
// ì˜ˆì‹œ: ê°™ì€ ë„ë©”ì¸ì— í”„ë¡ì‹œí•´ë‘ë©´ ìƒëŒ€ê²½ë¡œë¡œë„ OK
const WS_URL = `${location.protocol === "https:" ? "wss" : "ws"}://${location.host}/stt/stream`;
const HTTP_CHUNK_URL = `/stt/chunk`;
const HTTP_FINALIZE_URL = `/stt/finalize`;
// ê¸°ë³¸ ì–¸ì–´
const DEFAULT_LANG: "ko" | "en" = "ko";
// ===========================================

export default function ToolbarRecord({ editor, lang = DEFAULT_LANG }: { editor: any; lang?: "ko" | "en" }) {
  const [isRecording, setIsRecording] = useState(false);
  const [loading, setLoading] = useState(false);

  // ê³µí†µ ì°¸ì¡°
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const sessionIdRef = useRef<string>("");
  const liveNodeIdRef = useRef<string>("");

  // WSìš©
  const wsRef = useRef<WebSocket | null>(null);
  const isUsingWSRef = useRef<boolean>(false);

  // HTTPìš©
  const httpStopRef = useRef<null | (() => Promise<void>)>(null);

  const pickMimeType = () => {
    if (MediaRecorder.isTypeSupported("audio/ogg;codecs=opus")) return "audio/ogg;codecs=opus";
    if (MediaRecorder.isTypeSupported("audio/webm;codecs=opus")) return "audio/webm;codecs=opus";
    return ""; // ë¸Œë¼ìš°ì € ê¸°ë³¸ê°’
  };

  const insertLiveHolder = () => {
    const liveId = `live-${crypto.randomUUID()}`;
    liveNodeIdRef.current = liveId;
    editor?.commands?.insertContent(
      `<div id="${liveId}" class="ai-audio-note">
         <p><strong>ğŸ¤ ì‹¤ì‹œê°„ ë°›ì•„ì“°ê¸°â€¦</strong></p>
         <p class="live-text" style="opacity:.8"></p>
       </div>`
    );
  };

  const updatePartial = (text: string) => {
    const holder = document.getElementById(liveNodeIdRef.current);
    holder?.querySelector(".live-text")?.replaceChildren(document.createTextNode(text));
  };

  const insertFinalLine = (text: string) => {
    editor?.commands?.insertContent(`<p>${escapeHtml(text)}</p>`);
    updatePartial("");
  };

  const finishWithSummary = (payload: { audioUrl: string; transcript: string; summary: string }) => {
    const html = `
      <div class="ai-audio-note">
        <audio controls src="${payload.audioUrl}"></audio>
        <div class="ai-summary">
          <p><strong>ìš”ì•½</strong></p>
          <ul>${payload.summary.split(/\n+/).map((s) => `<li>${s}</li>`).join("")}</ul>
        </div>
        <details><summary>ì „ì²´ ìŠ¤í¬ë¦½íŠ¸</summary>
          <pre style="white-space:pre-wrap">${escapeHtml(payload.transcript)}</pre>
        </details>
      </div>`;
    editor?.commands?.insertContent(html);
    document.getElementById(liveNodeIdRef.current)?.remove();
  };

  const start = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mime = pickMimeType();

      insertLiveHolder();

      // 1) ë¨¼ì € WebSocket ì‹œë„
      try {
        await startWS(stream, mime);
        isUsingWSRef.current = true;
      } catch (e) {
        // 2) ì‹¤íŒ¨ ì‹œ HTTP í´ë°±
        await startHTTP(stream, mime);
        isUsingWSRef.current = false;
      }

      setIsRecording(true);
    } catch (e) {
      alert("ë§ˆì´í¬ ê¶Œí•œ/ì—°ê²° ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”");
      console.error(e);
    }
  };

  const stop = async () => {
    setLoading(true);
    try {
      // ë…¹ìŒ/ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
      mediaRecorderRef.current?.stop();
      mediaRecorderRef.current?.stream.getTracks().forEach((t) => t.stop());
      mediaRecorderRef.current = null;

      if (isUsingWSRef.current) {
        // WS ëª¨ë“œ
        if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
          wsRef.current.send(JSON.stringify({ type: "stop", sessionId: sessionIdRef.current }));
        }
        // ì„œë²„ê°€ summaryë¥¼ ë³´ë‚´ê³  closeí•  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°
        setTimeout(() => wsRef.current?.close(), 4000);
      } else {
        // HTTP ëª¨ë“œ
        if (httpStopRef.current) await httpStopRef.current();
      }
    } finally {
      setIsRecording(false);
      setLoading(false);
    }
  };

  // ---- WebSocket ëª¨ë“œ ----
  const startWS = async (stream: MediaStream, mime: string) =>
    new Promise<void>((resolve, reject) => {
      const codec =
        mime.includes("ogg") ? "ogg_opus" : mime.includes("webm") ? "webm_opus" : "unknown";
      const ws = new WebSocket(`${WS_URL}?lang=${lang}&codec=${codec}`);
      ws.binaryType = "arraybuffer";
      wsRef.current = ws;
      sessionIdRef.current = crypto.randomUUID();

      ws.onopen = () => {
        ws.send(
          JSON.stringify({
            type: "start",
            sessionId: sessionIdRef.current,
            contentType: mime || "audio/webm;codecs=opus",
          })
        );
        // onopen ëœ ì‹œì ì— MediaRecorder ì‹œì‘
        const mr = new MediaRecorder(stream, mime ? { mimeType: mime } : undefined);
        mediaRecorderRef.current = mr;
        mr.ondataavailable = (e) => {
          if (e.data && e.data.size > 0 && ws.readyState === WebSocket.OPEN) ws.send(e.data);
        };
        mr.start(3000); // 3ì´ˆ ì²­í¬
        resolve();
      };

      ws.onerror = () => reject(new Error("WS ì—°ê²° ì‹¤íŒ¨"));

      ws.onmessage = (evt) => {
        // ì„œë²„ ë©”ì‹œì§€ ê·œì•½: partial / final / summary
        try {
          const msg = JSON.parse(evt.data);
          if (msg.type === "partial") updatePartial(msg.text);
          else if (msg.type === "final") insertFinalLine(msg.text);
          else if (msg.type === "summary") finishWithSummary(msg);
        } catch {
          // ë°”ì´ë„ˆë¦¬ pong ë“±ì€ ë¬´ì‹œ
        }
      };
    });

  // ---- HTTP í´ë°± ëª¨ë“œ ----
  const startHTTP = async (stream: MediaStream, mime: string) => {
    sessionIdRef.current = crypto.randomUUID();
    const mr = new MediaRecorder(stream, mime ? { mimeType: mime } : undefined);
    mediaRecorderRef.current = mr;

    mr.ondataavailable = async (e) => {
      if (!e.data || e.data.size === 0) return;
      const fd = new FormData();
      fd.append("audio", e.data, `chunk.${mime.includes("ogg") ? "ogg" : "webm"}`);
      fd.append("sessionId", sessionIdRef.current);
      fd.append("lang", lang);

      try {
        const res = await fetch(HTTP_CHUNK_URL, { method: "POST", body: fd });
        const data = await res.json(); // { partial?: string, final?: string }
        if (data.partial) updatePartial(data.partial);
        if (data.final) insertFinalLine(data.final);
      } catch (err) {
        console.warn("ì²­í¬ ì—…ë¡œë“œ ì‹¤íŒ¨", err);
      }
    };

    mr.start(3000);

    // stop í•¸ë“¤ëŸ¬ ì €ì¥
    httpStopRef.current = async () => {
      try {
        const res = await fetch(`${HTTP_FINALIZE_URL}?sessionId=${sessionIdRef.current}`, {
          method: "POST",
        });
        const fin = await res.json(); // { audioUrl, transcript, summary }
        finishWithSummary(fin);
      } catch (err) {
        console.error("finalize ì‹¤íŒ¨", err);
      }
    };
  };

  useEffect(() => {
    return () => {
      mediaRecorderRef.current?.stream.getTracks().forEach((t) => t.stop());
      if (wsRef.current && wsRef.current.readyState <= 1) wsRef.current.close();
    };
  }, []);

  return (
    <button
      onClick={isRecording ? stop : start}
      className={`px-2 py-1 rounded ${isRecording ? "bg-red-500 text-white" : "bg-gray-100"}`}
      title={isRecording ? "ë…¹ìŒ ì¢…ë£Œ" : "ë…¹ìŒ ì‹œì‘"}
      disabled={loading}
    >
      {isRecording ? <PiStopFill size={18} /> : <PiMicrophoneFill size={18} />}
      <span className="ml-1">{loading ? "ì²˜ë¦¬ ì¤‘â€¦" : isRecording ? "ì¢…ë£Œ" : "ë…¹ìŒ"}</span>
    </button>
  );
}

function escapeHtml(s: string) {
  return s
    .replaceAll("&", "&amp;")
    .replaceAll("<", "&lt;")
    .replaceAll(">", "&gt;")
    .replaceAll('"', "&quot;");
}
